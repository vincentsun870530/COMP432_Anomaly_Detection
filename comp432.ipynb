{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vincentsun870530/COMP432_Anomaly_Detection/blob/final_encoder_random_matrix/comp432.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEA4SpSOsuId"
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# numpy, pandas and matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksP3LOxqsuId"
   },
   "source": [
    "### Dataset cleaning and reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tKoeKcYsuId"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/PRSA_data_2010.1.1-2014.12.31.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgbRjIDWsuId"
   },
   "outputs": [],
   "source": [
    "# Create timestamp\n",
    "data[\"timestamp\"] = pd.to_datetime(data[[\"year\", \"month\", \"day\", \"hour\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a310x-essuId"
   },
   "outputs": [],
   "source": [
    "data.drop([\"No\"], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne84L_QXsuId"
   },
   "outputs": [],
   "source": [
    "# Set timestamp as a new index\n",
    "data = data.set_index(\"timestamp\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPndr6gzsuIe"
   },
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to6IpwcWsuIe"
   },
   "outputs": [],
   "source": [
    "# Drop rows with NAN value \n",
    "data = data.dropna()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxdM_qGTsuIe"
   },
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTACXsXKsuIe"
   },
   "outputs": [],
   "source": [
    "# Factorize string data to integer \n",
    "data.loc[:, 'cbwd'] = pd.factorize(data.loc[:, 'cbwd'])[0]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQwzlgoXsuIf"
   },
   "source": [
    "### Data static summary and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mlb9sjPsuIf"
   },
   "outputs": [],
   "source": [
    "# Summarize key columns\n",
    "print(data[['pm2.5', 'DEWP', 'TEMP', 'PRES']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXRETSl0suIf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show how pm2.5 value looks like\n",
    "plt.figure(figsize=[16, 8])\n",
    "data['pm2.5'].plot(kind='line',color='green',grid=True)\n",
    "plt.title(\"PM2.5 with timestamp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR25VKFSsuIf"
   },
   "outputs": [],
   "source": [
    "# Show one month zoom in pm2.5 data\n",
    "plt.figure(figsize=[16, 8])\n",
    "data['pm2.5'][:700].plot(kind='line',color='green', grid=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1uv0XjxsuIf"
   },
   "outputs": [],
   "source": [
    "# plot the data distribution\n",
    "content_list = ['pm2.5', 'TEMP', 'DEWP', 'PRES', 'cbwd', 'Iws', 'Is', 'Ir']\n",
    "title_list = ['PM2.5 Concentration Distribution', 'Temperature Distribution', 'Dew Point Distribution', \\\n",
    "             'Pressure Distribution', 'Combined Wind Direction Distribution', 'Cumulated wind speed (m/s) Distribution', \\\n",
    "             'Cumulated Hours Of Snow Distribution', 'Cumulated Hours Of Rnow Distribution']\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "for i in range(len(content_list)):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.hist(data[content_list[i]], bins='auto')\n",
    "    plt.title(title_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z6osaT_s5dz"
   },
   "outputs": [],
   "source": [
    "# PM2.5 distribution\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.hist(data['pm2.5'], bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X0MLq5-suIg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multivariate Plots\n",
    "scatter_matrix(data[['pm2.5','TEMP','DEWP','PRES']],figsize=[16,16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AoPOVutsuIg"
   },
   "outputs": [],
   "source": [
    "# Zoom in the relation between temp and pm2.5\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.scatter(data['TEMP'], data['pm2.5'], marker= \"o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6v-5y0ossuIg"
   },
   "outputs": [],
   "source": [
    "# Zoom in the relation between PRES and pm2.5\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.scatter(data['PRES'], data['pm2.5'], marker= \"o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PENX05MUsuIg"
   },
   "outputs": [],
   "source": [
    "# Zoom in the relation between Iws and pm2.5\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.scatter(data['Iws'], data['pm2.5'], marker= \"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnvOkxKKsuIg"
   },
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVKj32ErsuIg"
   },
   "outputs": [],
   "source": [
    "# Sign a new column\n",
    "data = data.assign(anom=pd.Series(np.zeros(len(data), dtype=np.int)).values)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPoQdpwrsuIg"
   },
   "outputs": [],
   "source": [
    "df25 = data.loc[:, 'pm2.5']\n",
    "df25[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy7J2XRLsuIg"
   },
   "outputs": [],
   "source": [
    "# Different rolling window for labeling\n",
    "# Rolling window 12hrs\n",
    "df25_12_column = df25 - df25.rolling(12).mean()\n",
    "df25_12_column.name = 'diff_12hr_pm2.5'\n",
    "df25_12_column.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZoJ75apsuIg"
   },
   "outputs": [],
   "source": [
    "# Rolling window 24hrs\n",
    "df25_24_column = df25 - df25.rolling(24).mean()\n",
    "df25_24_column.name = 'diff_24hr_pm2.5'\n",
    "df25_24_column.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EabsYResuIg"
   },
   "outputs": [],
   "source": [
    "# Rolling window 48hrs\n",
    "df25_48_column = df25 - df25.rolling(48).mean()\n",
    "df25_48_column.name = 'diff_48hr_pm2.5'\n",
    "df25_48_column.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLMtErqUsuIg"
   },
   "outputs": [],
   "source": [
    "# Rolling window 144hrs\n",
    "df25_144_column = df25 - df25.rolling(144).mean()\n",
    "df25_144_column.name = 'diff_144hr_pm2.5'\n",
    "df25_144_column.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9rHxKHbsuIh"
   },
   "outputs": [],
   "source": [
    "# Declear window list\n",
    "window_list = [df25_12_column, df25_24_column, df25_48_column, df25_144_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4S5gVhMysuIh"
   },
   "outputs": [],
   "source": [
    "def get_new_dataframe_with_anomaly_label(original_dataset, window_column_series):\n",
    "    '''\n",
    "    This function gets an original pm2.5 dataframe and a pm2.5 diff series, then join it by same timestamp index. Return a dataframe contain pm2.5 dataframe with pm2.5 diff series.\n",
    "    original_dataset: pandas dataframe\n",
    "    window_column_series: pandas series\n",
    "    '''\n",
    "    newdata = pd.concat([data, window_column_series], axis=1)\n",
    "    newdata.columns.values[-1] = 'diff_pm_2.5'\n",
    "    newdata.loc[newdata['diff_pm_2.5'] >= 3*(newdata['diff_pm_2.5']).std(),'anom'] = 1\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(newdata['pm2.5'], markevery=[newdata['anom']==1], marker='x', markeredgecolor='red', color='green',markersize=10)\n",
    "    print('{0} total anomaly numbers : {1}'.format(window_column_series.name,len(newdata[newdata['anom']==1])))\n",
    "    plt.title('Window size : {0}'.format(window_column_series.name))\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhyGdziHsuIh"
   },
   "outputs": [],
   "source": [
    "newdata_list = []\n",
    "for i in window_list:\n",
    "    newdata_list.append(get_new_dataframe_with_anomaly_label(data, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "holZ1hbJz5oO"
   },
   "source": [
    "### Choose the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weTxU3TGsuIh"
   },
   "outputs": [],
   "source": [
    "# we use the first dataset in newdata_list in our project\n",
    "newdata = newdata_list[3]\n",
    "# drop the first few lines with NaN in diff_pm_2.5\n",
    "newdata = newdata.dropna()\n",
    "# make a seperate tag dataframe\n",
    "tag = newdata['anom'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the high dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5RUHuvKsuIh"
   },
   "outputs": [],
   "source": [
    "# this part is refer to \"https://www.kaggle.com/robinteuwens/anomaly-detection-with-auto-encoders\"\n",
    "# manual parameter \n",
    "RATIO_TO_ANOMALY = 10\n",
    "\n",
    "# splitting by class\n",
    "anomaly = newdata[newdata.anom == 1]\n",
    "normal = newdata[newdata.anom == 0]\n",
    "\n",
    "# undersample clean transactions\n",
    "normal_undersampled = normal.sample(\n",
    "    int(len(anomaly) * RATIO_TO_ANOMALY),\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# concatenate with fraud transactions into a single dataframe\n",
    "visualisation_initial = pd.concat([anomaly, normal_undersampled])\n",
    "column_names = list(visualisation_initial.drop('anom', axis=1).columns)\n",
    "\n",
    "# isolate features from labels \n",
    "features, labels = visualisation_initial.drop('anom', axis=1).values, \\\n",
    "                   visualisation_initial.anom.values\n",
    "\n",
    "\n",
    "def tsne_scatter(features, labels, dimensions=2, save_as='graph.png'):\n",
    "    if dimensions not in (2, 3):\n",
    "        raise ValueError('tsne_scatter can only plot in 2d or 3d')\n",
    "    # t-SNE dimensionality reduction\n",
    "    features_embedded = TSNE(n_components=dimensions, random_state=RANDOM_SEED).fit_transform(features)\n",
    "    # initialising the plot\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    # counting dimensions\n",
    "    if dimensions == 3: ax = fig.add_subplot(111, projection='3d')\n",
    "    # plotting data\n",
    "    ax.scatter(\n",
    "        *zip(*features_embedded[np.where(labels==1)]),\n",
    "        marker='o',\n",
    "        color='r',\n",
    "        s=2,\n",
    "        alpha=0.7,\n",
    "        label='Anomaly'\n",
    "    )\n",
    "    ax.scatter(\n",
    "        *zip(*features_embedded[np.where(labels==0)]),\n",
    "        marker='o',\n",
    "        color='g',\n",
    "        s=2,\n",
    "        alpha=0.3,\n",
    "        label='Normal'\n",
    "    )\n",
    "                         \n",
    "    # storing it to be displayed later\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(save_as)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwZraPfesuIh"
   },
   "outputs": [],
   "source": [
    "# print the t-sne\n",
    "tsne_scatter(features, labels, dimensions=2, save_as='tsne_initial_2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splite data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6D277uosuIi"
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines.\n",
    "# split data into three groups: training, validation, testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_data, testing_data, training_data_tag, testing_data_tag = train_test_split(newdata, tag, test_size=0.2, random_state=42)\n",
    "pure_training_data, validation_training_data, pure_training_tag, validation_training_tag = train_test_split(training_data, training_data_tag, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data and drop unnecessarily columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmu36ogesuIi"
   },
   "outputs": [],
   "source": [
    "# generate normal/anomaly data mask\n",
    "normal_mask = pure_training_data['anom']==0\n",
    "anomaly_mask = pure_training_data['anom']==1\n",
    "\n",
    "# seperate the normal tags from anomaly tags for training group\n",
    "normal_pure_training_tag = pure_training_tag[normal_mask]\n",
    "anomaly_pure_training_tag = pure_training_tag[anomaly_mask]\n",
    "\n",
    "# normalize the pure training data\n",
    "pure_training_data=(pure_training_data-pure_training_data.mean())/pure_training_data.std()\n",
    "\n",
    "# normalize the validation data\n",
    "validation_training_data=(validation_training_data-validation_training_data.mean())/validation_training_data.std()\n",
    "\n",
    "# normalize the testing data\n",
    "testing_data = (testing_data-testing_data.mean())/testing_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKSVSQAbsuIi"
   },
   "outputs": [],
   "source": [
    "# the autoencoder does not need to know the tag information and some other information for tag purpose, so drop it\n",
    "pure_training_data.drop('anom',axis=1,inplace=True)\n",
    "pure_training_data.drop('diff_pm_2.5',axis=1,inplace=True)\n",
    "\n",
    "validation_training_data.drop('anom',axis=1,inplace=True)\n",
    "validation_training_data.drop('diff_pm_2.5',axis=1,inplace=True)\n",
    "\n",
    "testing_data.drop('anom',axis=1,inplace=True)\n",
    "testing_data.drop('diff_pm_2.5',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFNY2PivsuIi"
   },
   "outputs": [],
   "source": [
    "# seperate the dataframe for normal training data and anomaly training data\n",
    "df_normal = pure_training_data[normal_mask]\n",
    "df_anomaly = pure_training_data[anomaly_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ9Nqd4LsuIi"
   },
   "outputs": [],
   "source": [
    "# make dataframe to np arrays\n",
    "x_normal_train = df_normal.values\n",
    "X_anomaly = df_anomaly.values\n",
    "x_normal_validation = validation_training_data.values\n",
    "X_testing = testing_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbQw3ZPVsuIi"
   },
   "outputs": [],
   "source": [
    "# try different numbers of neurals for each layer to train autoencoder\n",
    "%%time\n",
    "model_list = []\n",
    "history_list = []\n",
    "hidden_layer_list = []\n",
    "for outlayer_dim in range(4, 12):\n",
    "    for midlayer_dim in range(3, outlayer_dim):\n",
    "        for inlayer_dim in range(2, midlayer_dim):\n",
    "            hidden_layer_list.append(F\"{outlayer_dim}:{midlayer_dim}:{inlayer_dim}:{midlayer_dim}:{outlayer_dim}\")\n",
    "            model = Sequential()\n",
    "            model.add(Dense(outlayer_dim, input_dim=x_normal_train.shape[1], activation='relu'))\n",
    "            model.add(Dense(midlayer_dim, activation='relu')) \n",
    "            model.add(Dense(inlayer_dim, activation='relu')) \n",
    "            model.add(Dense(midlayer_dim, activation='relu')) # latent code layer\n",
    "            model.add(Dense(outlayer_dim, activation='relu'))\n",
    "            model.add(Dense(x_normal_train.shape[1])) # Multiple output neurons\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            history = model.fit(x_normal_train, x_normal_train, \n",
    "                      epochs=100, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(x_normal_validation, x_normal_validation),\n",
    "                      shuffle=True)\n",
    "            model_list.append(model)\n",
    "            history_list.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QV6cXqjWsuIi"
   },
   "outputs": [],
   "source": [
    "def printCurve(x, y, title, xlabel, ylabel):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reconstruct data and generate reconstructed tag lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJdxxxW7suIi"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rec_score_list = []\n",
    "prc_score_list = []\n",
    "\n",
    "# for i in range(len(model_list)):\n",
    "for i in range(len(model_list)):\n",
    "    model = model_list[i]\n",
    "    history = history_list[i]\n",
    "    \n",
    "    # reconstructe the x_normal_validation group\n",
    "    pred5 = model.predict(x_normal_validation)\n",
    "    score5 = np.sqrt(metrics.mean_squared_error(pred5,x_normal_validation))\n",
    "    \n",
    "    # this dataframe shows the difference between the actural pm2.5 and the reconstructed pm2.5\n",
    "    df_diff = x_normal_validation[:, 4] - pred5[:, 4]\n",
    "    diff = np.absolute(df_diff)\n",
    "    \n",
    "    # actural numbers of anomaly data classified by the \"rule\" we set\n",
    "    true_tag = validation_training_tag.values.astype(np.int)\n",
    "    \n",
    "    threshold = np.arange(0.1, 6, 0.1)\n",
    "    rec_score = np.zeros(len(threshold))\n",
    "    pred_tag = np.zeros(len(threshold))\n",
    "    prc_score = np.zeros(len(threshold))\n",
    "    \n",
    "    # generate predicted tag\n",
    "    for i in range(len(threshold)):\n",
    "        pred_tag = diff >= threshold[i]\n",
    "        rec_score[i] = sklearn.metrics.recall_score(true_tag, pred_tag)\n",
    "        prc_score[i] = sklearn.metrics.precision_score(true_tag, pred_tag)\n",
    "        pred_tag = np.zeros(len(threshold))\n",
    "    \n",
    "    rec_score_list.append(rec_score)\n",
    "    prc_score_list.append(prc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkACUzBgsuIi"
   },
   "outputs": [],
   "source": [
    "def printCurve(x_list, y_list, title_list, xlabel, ylabel):\n",
    "    plt.figure(figsize=(20,120))\n",
    "    for i in range(len(x_list)):\n",
    "        plt.subplot(24, 5, i+1)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.plot(x_list[i], y_list[i])\n",
    "        plt.title(title_list[i] + F\" {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print precision-recall curves for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUNjhr8csuIi"
   },
   "outputs": [],
   "source": [
    "# plot all the precision-recall curves for all 120 models\n",
    "printCurve(rec_score_list, prc_score_list, hidden_layer_list, \"Recall\", \"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify best model and print RMSE informations for reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0F4wYeCsuIi"
   },
   "outputs": [],
   "source": [
    "# from visual check we found the model 87 has large auroc\n",
    "best_model_index = 87\n",
    "print(F\"the best model is {hidden_layer_list[best_model_index]}\")\n",
    "model_list[best_model_index].summary()\n",
    "print(F\"model {best_model_index} training loss = {history_list[best_model_index].history['loss'][-1]}\")\n",
    "print(F\"model {best_model_index} validation loss = {history_list[best_model_index].history['val_loss'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2saJcs3NsuIi"
   },
   "outputs": [],
   "source": [
    "model = model_list[best_model_index]\n",
    "history = history_list[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtGravk1suIi"
   },
   "outputs": [],
   "source": [
    "# print the loss with epochs\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxAPAn9OsuIi"
   },
   "outputs": [],
   "source": [
    "# check the root mean square for reconstructed testing data\n",
    "pred1 = model.predict(X_testing)\n",
    "score1 = np.sqrt(metrics.mean_squared_error(pred1,X_testing))\n",
    "print(f\"Test smaples Score (RMSE): {score1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytFoLHTZ41WV"
   },
   "outputs": [],
   "source": [
    "# check the root mean square for reconstructed training data(include normal and amormaly data)\n",
    "training_data2=(training_data-training_data.mean())/training_data.std()\n",
    "training_data2.drop('anom',axis=1,inplace=True)\n",
    "training_data2.drop('diff_pm_2.5',axis=1,inplace=True)\n",
    "pred2 = model.predict(training_data2)\n",
    "score2 = np.sqrt(metrics.mean_squared_error(pred2,training_data2))\n",
    "print(f\"Test smaples Score (RMSE): {score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqYF5RAS7Cch"
   },
   "outputs": [],
   "source": [
    "# check the root mean square for reconstructed anomaly data in training group(this part does not involved in training)\n",
    "pred3 = model.predict(X_anomaly)\n",
    "score3 = np.sqrt(metrics.mean_squared_error(pred3,X_anomaly))\n",
    "print(f\"Test smaples Score (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate reconstructed tags for comparement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voJFf-16suIi"
   },
   "outputs": [],
   "source": [
    "# this dataframe shows the difference between the actural pm2.5 and the reconstructed pm2.5\n",
    "df_diff = X_testing[:, 4] - pred1[:, 4]\n",
    "diff = np.absolute(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyz9lB6usuIi"
   },
   "outputs": [],
   "source": [
    "# actural numbers of anomaly data classified by the \"rule\" we set\n",
    "true_tag = testing_data_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-ktPFE2suIi"
   },
   "outputs": [],
   "source": [
    "# for every candidate threshold value, a recall list and a precision list are generated\n",
    "threshold = np.arange(0.1, 6, 0.1)\n",
    "rec_score = np.zeros(len(threshold))\n",
    "prc_score = np.zeros(len(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w7PGjDKsuIi"
   },
   "outputs": [],
   "source": [
    "pred_tag_list = []\n",
    "for i in range(len(threshold)):\n",
    "    # if the difference in pm2.5 is larger than the candidate threshold value, the tag is set to 1\n",
    "    pred_tag = (diff >= threshold[i])\n",
    "    pred_tag_list.append(pred_tag)\n",
    "    # use true tags and predicted tags to generate a recall score list and a precision score list\n",
    "    rec_score[i] = sklearn.metrics.recall_score(true_tag, pred_tag)\n",
    "    prc_score[i] = sklearn.metrics.precision_score(true_tag, pred_tag)\n",
    "    pred_tag = np.zeros(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix for each threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mRsxHjwsuIi"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "con_matrix = []\n",
    "for i in range(len(pred_tag_list)):\n",
    "    # for each threshold value, a confusion matrix is generated and appended into a list\n",
    "    cm = confusion_matrix(true_tag, pred_tag_list[i])\n",
    "    con_matrix.append(cm)\n",
    "\n",
    "# print all the confusion matrix for check\n",
    "plt.figure(figsize=(20, 120))\n",
    "def pltCM(cm_list, title_list):\n",
    "    for i in range(len(cm_list)):\n",
    "        ax = plt.subplot(15, 4, i+1)\n",
    "        ax.set_title(\"thres = {:2.2f}\".format(title_list[i]))\n",
    "        df_cm = pd.DataFrame(cm_list[i])\n",
    "        sn.set(font_scale=1.4) # for label size\n",
    "        sn.heatmap(df_cm, annot=True) # font size\n",
    "pltCM(con_matrix, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the final threshold value and print curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR7KXCoH-R8V"
   },
   "outputs": [],
   "source": [
    "# from the above printed information we choose the NO.29 threshold value in list(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM4xDDfKsuIj"
   },
   "outputs": [],
   "source": [
    "def printCuv(x, y, title, xlabel, ylabel):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmNk69jbsuIj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printCuv(rec_score, prc_score, \"2 class Precision-Recall curve\", \"Recall\", \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w62GTUqnsuIj"
   },
   "outputs": [],
   "source": [
    "printCuv(threshold, prc_score, \"2 class Threshold-Precision curve\", \"threshold\", \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxuSsvl_suIj"
   },
   "outputs": [],
   "source": [
    "printCuv(threshold, rec_score, \"2 class Threshold-Recall curve\", \"threshold\", \"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP2Q-jxJsuIj"
   },
   "outputs": [],
   "source": [
    "print(F\"threshold value we choose is {threshold[29]}, with precision {prc_score_list[best_model_index][29]} and recall {rec_score_list[best_model_index][29]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIF5XDWasuIj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "comp432.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
