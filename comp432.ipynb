{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "comp432.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentsun870530/COMP432_Anomaly_Detection/blob/final_encoder_random_matrix/comp432.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEA4SpSOsuId"
      },
      "source": [
        "# sklearn\n",
        "import sklearn\n",
        "import sklearn.preprocessing\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# numpy, pandas and matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from IPython.display import display, HTML \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "RANDOM_SEED = 0\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksP3LOxqsuId"
      },
      "source": [
        "### Dataset cleaning and reformatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tKoeKcYsuId"
      },
      "source": [
        "data = pd.read_csv('data/PRSA_data_2010.1.1-2014.12.31.csv')\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgbRjIDWsuId"
      },
      "source": [
        "# Create timestamp\n",
        "data[\"timestamp\"] = pd.to_datetime(data[[\"year\", \"month\", \"day\", \"hour\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a310x-essuId"
      },
      "source": [
        "data.drop([\"No\"], axis=1, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne84L_QXsuId"
      },
      "source": [
        "# Set timestamp as a new index\n",
        "data = data.set_index(\"timestamp\")\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPndr6gzsuIe"
      },
      "source": [
        "# Check dataset shape\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to6IpwcWsuIe"
      },
      "source": [
        "# Drop rows with NAN value \n",
        "data = data.dropna()\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxdM_qGTsuIe"
      },
      "source": [
        "# Check dataset shape\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTACXsXKsuIe"
      },
      "source": [
        "# Factorize string data to integer \n",
        "data.loc[:, 'cbwd'] = pd.factorize(data.loc[:, 'cbwd'])[0]\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQwzlgoXsuIf"
      },
      "source": [
        "### Data static summary and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mlb9sjPsuIf"
      },
      "source": [
        "# Summarize key columns\n",
        "print(data[['pm2.5', 'DEWP', 'TEMP', 'PRES']].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mXRETSl0suIf"
      },
      "source": [
        "# Show how pm2.5 value looks like\n",
        "plt.figure(figsize=[16, 8])\n",
        "data['pm2.5'].plot(kind='line',color='green',grid=True)\n",
        "plt.title(\"PM2.5 with timestamp\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR25VKFSsuIf"
      },
      "source": [
        "# Show one month zoom in pm2.5 data\n",
        "plt.figure(figsize=[16, 8])\n",
        "data['pm2.5'][:700].plot(kind='line',color='green', grid=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1uv0XjxsuIf"
      },
      "source": [
        "# plot the data distribution\n",
        "content_list = ['pm2.5', 'TEMP', 'DEWP', 'PRES', 'cbwd', 'Iws', 'Is', 'Ir']\n",
        "title_list = ['PM2.5 Concentration Distribution', 'Temperature Distribution', 'Dew Point Distribution', \\\n",
        "             'Pressure Distribution', 'Combined Wind Direction Distribution', 'Cumulated wind speed (m/s) Distribution', \\\n",
        "             'Cumulated Hours Of Snow Distribution', 'Cumulated Hours Of Rnow Distribution']\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "for i in range(len(content_list)):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.hist(data[content_list[i]], bins='auto')\n",
        "    plt.title(title_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z6osaT_s5dz"
      },
      "source": [
        "# PM2.5 distribution\n",
        "plt.figure(figsize=[16, 8])\n",
        "plt.hist(data['pm2.5'], bins='auto');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9X0MLq5-suIg"
      },
      "source": [
        "# Multivariate Plots\n",
        "scatter_matrix(data[['pm2.5','TEMP','DEWP','PRES']],figsize=[16,16])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AoPOVutsuIg"
      },
      "source": [
        "# Zoom in the relation between temp and pm2.5\n",
        "plt.figure(figsize=[16, 8])\n",
        "plt.scatter(data['TEMP'], data['pm2.5'], marker= \"o\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v-5y0ossuIg"
      },
      "source": [
        "# Zoom in the relation between PRES and pm2.5\n",
        "plt.figure(figsize=[16, 8])\n",
        "plt.scatter(data['PRES'], data['pm2.5'], marker= \"o\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PENX05MUsuIg"
      },
      "source": [
        "# Zoom in the relation between Iws and pm2.5\n",
        "plt.figure(figsize=[16, 8])\n",
        "plt.scatter(data['Iws'], data['pm2.5'], marker= \"o\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnvOkxKKsuIg"
      },
      "source": [
        "### Data wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVKj32ErsuIg"
      },
      "source": [
        "# Sign a new column\n",
        "data = data.assign(anom=pd.Series(np.zeros(len(data), dtype=np.int)).values)\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPoQdpwrsuIg"
      },
      "source": [
        "df25 = data.loc[:, 'pm2.5']\n",
        "df25[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy7J2XRLsuIg"
      },
      "source": [
        "# Different rolling window for labeling\n",
        "# Rolling window 12hrs\n",
        "df25_12_column = df25 - df25.rolling(12).mean()\n",
        "df25_12_column.name = 'diff_12hr_pm2.5'\n",
        "df25_12_column.hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZoJ75apsuIg"
      },
      "source": [
        "# Rolling window 24hrs\n",
        "df25_24_column = df25 - df25.rolling(24).mean()\n",
        "df25_24_column.name = 'diff_24hr_pm2.5'\n",
        "df25_24_column.hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EabsYResuIg"
      },
      "source": [
        "# Rolling window 48hrs\n",
        "df25_48_column = df25 - df25.rolling(48).mean()\n",
        "df25_48_column.name = 'diff_48hr_pm2.5'\n",
        "df25_48_column.hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLMtErqUsuIg"
      },
      "source": [
        "# Rolling window 144hrs\n",
        "df25_144_column = df25 - df25.rolling(144).mean()\n",
        "df25_144_column.name = 'diff_144hr_pm2.5'\n",
        "df25_144_column.hist();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9rHxKHbsuIh"
      },
      "source": [
        "# Declear window list\n",
        "window_list = [df25_12_column, df25_24_column, df25_48_column, df25_144_column]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S5gVhMysuIh"
      },
      "source": [
        "def get_new_dataframe_with_anomaly_label(original_dataset, window_column_series):\n",
        "    '''\n",
        "    This function gets an original pm2.5 dataframe and a pm2.5 diff series, then join it by same timestamp index. Return a dataframe contain pm2.5 dataframe with pm2.5 diff series.\n",
        "    original_dataset: pandas dataframe\n",
        "    window_column_series: pandas series\n",
        "    '''\n",
        "    newdata = pd.concat([data, window_column_series], axis=1)\n",
        "    newdata.columns.values[-1] = 'diff_pm_2.5'\n",
        "    newdata.loc[newdata['diff_pm_2.5'] >= 3*(newdata['diff_pm_2.5']).std(),'anom'] = 1\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.plot(newdata['pm2.5'], markevery=[newdata['anom']==1], marker='x', markeredgecolor='red', color='green',markersize=10)\n",
        "    print('{0} total anomaly numbers : {1}'.format(window_column_series.name,len(newdata[newdata['anom']==1])))\n",
        "    plt.title('Window size : {0}'.format(window_column_series.name))\n",
        "    return newdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhyGdziHsuIh"
      },
      "source": [
        "newdata_list = []\n",
        "for i in window_list:\n",
        "    newdata_list.append(get_new_dataframe_with_anomaly_label(data, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "holZ1hbJz5oO"
      },
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weTxU3TGsuIh"
      },
      "source": [
        "# we use the first dataset in newdata_list in our project\n",
        "newdata = newdata_list[3]\n",
        "# drop the first few lines with NaN in diff_pm_2.5\n",
        "newdata = newdata.dropna()\n",
        "tag = newdata['anom'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5RUHuvKsuIh"
      },
      "source": [
        "# this part is refer to \"https://www.kaggle.com/robinteuwens/anomaly-detection-with-auto-encoders\"\n",
        "# manual parameter \n",
        "RATIO_TO_ANOMALY = 10\n",
        "\n",
        "# splitting by class\n",
        "anomaly = newdata[newdata.anom == 1]\n",
        "normal = newdata[newdata.anom == 0]\n",
        "\n",
        "# undersample clean transactions\n",
        "normal_undersampled = normal.sample(\n",
        "    int(len(anomaly) * RATIO_TO_ANOMALY),\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# concatenate with fraud transactions into a single dataframe\n",
        "visualisation_initial = pd.concat([anomaly, normal_undersampled])\n",
        "column_names = list(visualisation_initial.drop('anom', axis=1).columns)\n",
        "\n",
        "# isolate features from labels \n",
        "features, labels = visualisation_initial.drop('anom', axis=1).values, \\\n",
        "                   visualisation_initial.anom.values\n",
        "\n",
        "\n",
        "def tsne_scatter(features, labels, dimensions=2, save_as='graph.png'):\n",
        "    if dimensions not in (2, 3):\n",
        "        raise ValueError('tsne_scatter can only plot in 2d or 3d')\n",
        "    # t-SNE dimensionality reduction\n",
        "    features_embedded = TSNE(n_components=dimensions, random_state=RANDOM_SEED).fit_transform(features)\n",
        "    # initialising the plot\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    # counting dimensions\n",
        "    if dimensions == 3: ax = fig.add_subplot(111, projection='3d')\n",
        "    # plotting data\n",
        "    ax.scatter(\n",
        "        *zip(*features_embedded[np.where(labels==1)]),\n",
        "        marker='o',\n",
        "        color='r',\n",
        "        s=2,\n",
        "        alpha=0.7,\n",
        "        label='Anomaly'\n",
        "    )\n",
        "    ax.scatter(\n",
        "        *zip(*features_embedded[np.where(labels==0)]),\n",
        "        marker='o',\n",
        "        color='g',\n",
        "        s=2,\n",
        "        alpha=0.3,\n",
        "        label='Normal'\n",
        "    )\n",
        "                         \n",
        "    # storing it to be displayed later\n",
        "    plt.legend(loc='best')\n",
        "    plt.savefig(save_as)\n",
        "    plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwZraPfesuIh"
      },
      "source": [
        "# print the t-sne\n",
        "tsne_scatter(features, labels, dimensions=2, save_as='tsne_initial_2d.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6D277uosuIi"
      },
      "source": [
        "# Your code here. Aim for 2-3 lines.\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_data, testing_data, training_data_tag, testing_data_tag = train_test_split(newdata, tag, test_size=0.2, random_state=42)\n",
        "pure_training_data, validation_training_data, pure_training_tag, validation_training_tag = train_test_split(training_data, training_data_tag, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmu36ogesuIi"
      },
      "source": [
        "# generate normal/anomaly data mask\n",
        "normal_mask = pure_training_data['anom']==0\n",
        "anomaly_mask = pure_training_data['anom']==1\n",
        "\n",
        "normal_pure_training_tag = pure_training_tag[normal_mask]\n",
        "anomaly_pure_training_tag = pure_training_tag[anomaly_mask]\n",
        "\n",
        "# normalize the pure training data\n",
        "pure_training_data=(pure_training_data-pure_training_data.mean())/pure_training_data.std()\n",
        "\n",
        "# normalize the validation data\n",
        "validation_training_data=(validation_training_data-validation_training_data.mean())/validation_training_data.std()\n",
        "\n",
        "# normalize the testing data\n",
        "testing_data = (testing_data-testing_data.mean())/testing_data.std()\n",
        "\n",
        "# make a copy for seperate purpose\n",
        "whole_data = newdata.copy()\n",
        "whole_data.drop('anom',axis=1,inplace=True)\n",
        "whole_data_wot = whole_data.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKSVSQAbsuIi"
      },
      "source": [
        "# the autoencoder does not need to know the tag information and some other information for tag purpose, so drop it\n",
        "pure_training_data.drop('anom',axis=1,inplace=True)\n",
        "pure_training_data.drop('diff_pm_2.5',axis=1,inplace=True)\n",
        "\n",
        "validation_training_data.drop('anom',axis=1,inplace=True)\n",
        "validation_training_data.drop('diff_pm_2.5',axis=1,inplace=True)\n",
        "\n",
        "testing_data.drop('anom',axis=1,inplace=True)\n",
        "testing_data.drop('diff_pm_2.5',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFNY2PivsuIi"
      },
      "source": [
        "df_normal = pure_training_data[normal_mask]\n",
        "df_anomaly = pure_training_data[anomaly_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9Nqd4LsuIi"
      },
      "source": [
        "x_normal_train = df_normal.values\n",
        "X_anomaly = df_anomaly.values\n",
        "x_normal_validation = validation_training_data.values\n",
        "X_testing = testing_data.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbQw3ZPVsuIi"
      },
      "source": [
        "%%time\n",
        "model_list = []\n",
        "history_list = []\n",
        "hidden_layer_list = []\n",
        "for outlayer_dim in range(4, 12):\n",
        "    for midlayer_dim in range(3, outlayer_dim):\n",
        "        for inlayer_dim in range(2, midlayer_dim):\n",
        "            hidden_layer_list.append(F\"{outlayer_dim}:{midlayer_dim}:{inlayer_dim}:{midlayer_dim}:{outlayer_dim}\")\n",
        "            model = Sequential()\n",
        "            model.add(Dense(outlayer_dim, input_dim=x_normal_train.shape[1], activation='relu'))\n",
        "            model.add(Dense(midlayer_dim, activation='relu')) # latent code layer\n",
        "            model.add(Dense(inlayer_dim, activation='relu')) # latent code layer\n",
        "            model.add(Dense(midlayer_dim, activation='relu')) \n",
        "            model.add(Dense(outlayer_dim, activation='relu'))\n",
        "            model.add(Dense(x_normal_train.shape[1])) # Multiple output neurons\n",
        "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "            history = model.fit(x_normal_train, x_normal_train, \n",
        "                      epochs=100, \n",
        "                      batch_size=512,\n",
        "                      validation_data=(x_normal_validation, x_normal_validation),\n",
        "                      shuffle=True)\n",
        "            model_list.append(model)\n",
        "            history_list.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV6cXqjWsuIi"
      },
      "source": [
        "def printCurve(x, y, title, xlabel, ylabel):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.plot(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJdxxxW7suIi"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rec_score_list = []\n",
        "prc_score_list = []\n",
        "\n",
        "# for i in range(len(model_list)):\n",
        "for i in range(len(model_list)):\n",
        "    model = model_list[i]\n",
        "    history = history_list[i]\n",
        "    \n",
        "    pred5 = model.predict(x_normal_validation)\n",
        "    score5 = np.sqrt(metrics.mean_squared_error(pred5,x_normal_validation))\n",
        "    \n",
        "    # this dataframe shows the difference between the actural pm2.5 and the reconstructed pm2.5\n",
        "    df_diff = x_normal_validation[:, 4] - pred5[:, 4]\n",
        "    diff = np.absolute(df_diff)\n",
        "    \n",
        "    # actural numbers of anomaly data classified by the \"rule\" we set\n",
        "    true_tag = validation_training_tag.values.astype(np.int)\n",
        "    \n",
        "    threshold = np.arange(0.1, 6, 0.1)\n",
        "    rec_score = np.zeros(len(threshold))\n",
        "    pred_tag = np.zeros(len(threshold))\n",
        "    prc_score = np.zeros(len(threshold))\n",
        "    \n",
        "    for i in range(len(threshold)):\n",
        "        pred_tag = diff >= threshold[i]\n",
        "        rec_score[i] = sklearn.metrics.recall_score(true_tag, pred_tag)\n",
        "        prc_score[i] = sklearn.metrics.precision_score(true_tag, pred_tag)\n",
        "        pred_tag = np.zeros(len(threshold))\n",
        "    \n",
        "    rec_score_list.append(rec_score)\n",
        "    prc_score_list.append(prc_score)\n",
        "    \n",
        "#     printCurve(rec_score, prc_score, \"2 class Precision-Recall curve\", \"Recall\", \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkACUzBgsuIi"
      },
      "source": [
        "def printCurve(x_list, y_list, title_list, xlabel, ylabel):\n",
        "    plt.figure(figsize=(20,120))\n",
        "    for i in range(len(x_list)):\n",
        "        plt.subplot(24, 5, i+1)\n",
        "        plt.xlabel(xlabel)\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.plot(x_list[i], y_list[i])\n",
        "        plt.title(title_list[i] + F\" {i}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l5dRyeAJT-m"
      },
      "source": [
        "rec_score_list[68], prc_score_list[68]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffa8AoHFHDKp"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(rec_score_list[68], prc_score_list[68], s=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbAfIBcMveY0"
      },
      "source": [
        "from sklearn.metrics import auc\n",
        "temp = auc(rec_score_list[68], prc_score_list[68])\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuJnCDcWITro"
      },
      "source": [
        "len(prc_score_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUNjhr8csuIi"
      },
      "source": [
        "printCurve(rec_score_list, prc_score_list, hidden_layer_list, \"Recall\", \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP8CIb4isuIi"
      },
      "source": [
        "# auroc_list = auc(prc_score_list)\n",
        "\n",
        "auc_list = []\n",
        "for rec, prc in zip(rec_score_list, prc_score_list):\n",
        "  auc_list.append(auc(rec, prc))\n",
        "\n",
        "max_auroc = max(auroc_list)\n",
        "maxauroc_index_list = [i for i, j in enumerate(auroc_list) if j == max_auroc]\n",
        "best_classifier_index = maxauroc_index_list[0]\n",
        "\n",
        "print(F\"the best classifier is NO.{best_classifier_index} and the max auroc is {max_auroc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj03O5XWyOZH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unf2RNRNEBPc"
      },
      "source": [
        "prc_score_list[87].sum(), prc_score_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ1-g-8oC0ZA"
      },
      "source": [
        "rec_score_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSGtAQDL9iMT"
      },
      "source": [
        " best_classifier_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8bwBii_AQok"
      },
      "source": [
        "model_list[36].summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0F4wYeCsuIi"
      },
      "source": [
        "# best_model_index = best_classifier_index\n",
        "best_model_index = 36\n",
        "print(F\"the best model is {hidden_layer_list[best_model_index]}\")\n",
        "model_list[best_model_index].summary()\n",
        "print(F\"model {best_model_index} training loss = {history_list[best_model_index].history['loss'][-1]}\")\n",
        "print(F\"model {best_model_index} validation loss = {history_list[best_model_index].history['val_loss'][-1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2saJcs3NsuIi"
      },
      "source": [
        "model = model_list[best_model_index]\n",
        "history = history_list[best_model_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtGravk1suIi"
      },
      "source": [
        "# print the loss with epochs\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxAPAn9OsuIi"
      },
      "source": [
        "pred1 = model.predict(X_testing)\n",
        "score1 = np.sqrt(metrics.mean_squared_error(pred1,X_testing))\n",
        "print(f\"Test smaples Score (RMSE): {score1}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytFoLHTZ41WV"
      },
      "source": [
        "training_data2=(training_data-training_data.mean())/training_data.std()\n",
        "training_data2.drop('anom',axis=1,inplace=True)\n",
        "training_data2.drop('diff_pm_2.5',axis=1,inplace=True)\n",
        "pred2 = model.predict(training_data2)\n",
        "score2 = np.sqrt(metrics.mean_squared_error(pred2,training_data2))\n",
        "print(f\"Test smaples Score (RMSE): {score2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqYF5RAS7Cch"
      },
      "source": [
        "pred3 = model.predict(X_anomaly)\n",
        "score3 = np.sqrt(metrics.mean_squared_error(pred3,X_anomaly))\n",
        "print(f\"Test smaples Score (RMSE): {score3}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAlwp3so5uDQ"
      },
      "source": [
        "training_data.shape, X_testing.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voJFf-16suIi"
      },
      "source": [
        "# this dataframe shows the difference between the actural pm2.5 and the reconstructed pm2.5\n",
        "df_diff = X_testing[:, 4] - pred1[:, 4]\n",
        "diff = np.absolute(df_diff)\n",
        "# diff = df_diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyz9lB6usuIi"
      },
      "source": [
        "# actural numbers of anomaly data classified by the \"rule\" we set\n",
        "true_tag = testing_data_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ktPFE2suIi"
      },
      "source": [
        "threshold = np.arange(0.1, 6, 0.1)\n",
        "rec_score = np.zeros(len(threshold))\n",
        "# pred_tag = np.zeros(len(threshold))\n",
        "prc_score = np.zeros(len(threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BELJSJwPsuIi"
      },
      "source": [
        "\n",
        "#         plt.xlabel(xlabel)\n",
        "#         plt.ylabel(ylabel)\n",
        "#         plt.plot(x_list[i], y_list[i])\n",
        "#         plt.title(title_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w7PGjDKsuIi"
      },
      "source": [
        "pred_tag_list = []\n",
        "for i in range(len(threshold)):\n",
        "    pred_tag = (diff >= threshold[i])\n",
        "    pred_tag_list.append(pred_tag)\n",
        "    rec_score[i] = sklearn.metrics.recall_score(true_tag, pred_tag)\n",
        "    prc_score[i] = sklearn.metrics.precision_score(true_tag, pred_tag)\n",
        "    pred_tag = np.zeros(len(threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00pK_ICusuIi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mRsxHjwsuIi"
      },
      "source": [
        "for i in range(len(pred_tag_list)):\n",
        "    # plt.title(F\"Threshold value is {threshold[i]}\")\n",
        "    cm = confusion_matrix(true_tag, pred_tag_list[i])\n",
        "    print(F\"Threshold value is {threshold[i]} (index {i})\")\n",
        "    print(cm);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR7KXCoH-R8V"
      },
      "source": [
        "# from the above printed information we choose the NO.29 threshold value in list(3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM4xDDfKsuIj"
      },
      "source": [
        "def printCuv(x, y, title, xlabel, ylabel):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.plot(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "kmNk69jbsuIj"
      },
      "source": [
        "printCuv(rec_score, prc_score, \"2 class Precision-Recall curve\", \"Recall\", \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w62GTUqnsuIj"
      },
      "source": [
        "printCuv(threshold, prc_score, \"2 class Threshold-Precision curve\", \"threshold\", \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxuSsvl_suIj"
      },
      "source": [
        "printCuv(threshold, rec_score, \"2 class Threshold-Recall curve\", \"threshold\", \"Recall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP2Q-jxJsuIj"
      },
      "source": [
        "print(F\"threshold value we choose is {threshold[29]}, with precision {prc_score_list[36][29]} and recall {rec_score_list[36][29]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIF5XDWasuIj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}